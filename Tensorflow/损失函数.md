# 损失函数

标签（空格分隔）： Tensorflow

---

## 均方误差  （mean square error）：
$E=\frac{1}{2}\sum_{k}{(y_k-t_k)}^2$

* $y_k$: 神经网络的输出  
* $t_k$: 监督数据  
* $k$： 数据的维数  

## 交叉熵误差（cross entropy error）：  
$E=-\sum_{k}{t_klog{y_k}}$  

* $y_k$: 神经网络的输出  
* $t_k$: 监督数据  
* $k$： 数据的维数  
注：$t_k$中只有正确解标签的索引为1，其余均为0（one-hot)表示。因此，上述公式实际上只计算对应正确标签解的输出的自然对数。  
## mini-batch学习  
计算损失函数时，必须将所有的训练数据作为对象。之前的损失函数都是针对单个数据计算。如果要求所有训练数据的损失函数的总和，以交叉熵为例，公式如下： 

$E=-\frac{1}{N}\sum_n\sum_kt_{nk}logy_{nk}$  

